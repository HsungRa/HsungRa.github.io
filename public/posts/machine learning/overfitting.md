---
title: '什么是过拟合'
description: ''
name: ''
category: 'ML'
tags: ['machine learning','model training']
date: '2024/12/19 11:54:10'
published: true
---


> 转发自[IBM 《什么是过拟合》](https://www.ibm.com/cn-zh/topics/overfitting)
# 什么是过拟合？
在机器学习中，当算法与其训练数据过于接近甚至完全吻合时，就会发生过拟合，这会导致模型无法根据训练数据以外的任何数据做出准确的预测或结论。

过拟合违背了机器学习模型的目的。通过将模型泛化至新数据，最终我们能够每天使用机器学习算法做出预测，并对数据进行分类。

在构建机器学习算法时，会利用样本数据集来训练模型。但是，当模型针对样本数据训练时间过长或模型过于复杂时，它会开始学习数据集中的“噪声”或无关信息。当模型记住了噪声并过于贴近训练集时，模型就会变得“过拟合”，无法很好地泛化到新数据中。如果模型无法很好地泛化到新数据，则它将无法执行其预期的分类或预测任务。

低错误率和高方差是过拟合的明显标志。为了防止出现这种行为，通常会将部分训练数据集留作“测试集”，用来检查是否存在过拟合。如果训练数据的错误率较低，而测试数据的错误率较高，则表明存在过拟合。

# 过拟合与欠拟合
如果过度训练模型或模型过于复杂导致出现过拟合，那么逻辑上的预防应对措施就是提前暂停训练过程（也称为"早停法"），或者通过消除不太相关的输入来降低模型的复杂性。但是，如果过早暂停或排除太多重要特征，就可能会走向另一个极端 – 模型欠拟合。当模型没有训练足够长的时间，或者输入变量不够显著，无法确定输入变量和输出变量之间的有意义关系时，就会发生欠拟合。

在这两种情况下，模型都无法在训练数据集中确定主导趋势。因此，对于看不见的数据，欠拟合的泛化效果也很差。然而，与过拟合不同，欠拟合的模型在预测时的偏差较高，方差较小。这说明了偏差方差权衡，在欠拟合的模型转变为过拟合状态时，就会发生这种情况。随着模型不断学习，其偏差会减小，但在过拟合状态下，其方差可能会增加。拟合模型时，目标是在欠拟合和过拟合之间找到“最佳点”，以便确定主导趋势，并将其广泛应用于新数据集。

# 如何检测过拟合模型
要了解机器学习模型的准确性，必须测试模型的拟合度。K 折交叉验证是最常用的模型准确性评估技术之一。

在 K 折交叉验证中，数据被拆分为 k 个大小相等的子集，这些子集也称为“折叠”。其中一个“k 折”将充当测试集，也称为留出集或验证集，其余“折叠”则用于训练模型。不断重复这个过程，直到每个“折叠”都用作留出“折叠”。每次评估后，都会保留一个分数，在完成所有迭代后，会求这些分数的平均值，用于评估整个模型的性能。

# 如何避免过拟合
虽然使用线性模型有助于我们避免过拟合，但许多现实问题是非线性的。除了了解如何检测过拟合之外，了解如何避免过拟合也很重要。以下是一些可以用来防止过拟合的技术：

早停法：如前所述，这种方法是在模型开始学习模型内部噪声之前暂停训练。这种方法有可能过早停止训练过程，从而导致相反的欠拟合问题。在欠拟合和过拟合之间找到“最佳平衡点”是这里的最终目标。
使用更多数据进行训练：扩大训练集以包含更多数据，提供更多机会来解析输入和输出变量之间的主导关系，从而提高模型的准确性。也就是说，如果将干净的相关数据注入模型，这种方法更加有效。否则，可能会继续增加模型的复杂性，从而导致其过拟合。
数据增强：虽然最好将干净的相关数据注入到训练数据中，但有时会添加噪声数据来让模型更加稳定。然而，这种方法应该谨慎使用。
特征选择：构建模型时，会有许多用于预测给定结果的参数或特征，但很多时候，这些特征对其他特征而言可能是冗余的。特征选择是识别训练数据中最重要的特征，然后消除不相关或冗余特征的过程。这通常被误认为是降维，但其实是不同的。但是，这两种方法都有助于简化模型，以确定数据中的主导趋势。
正则化：如果模型过于复杂而导致过拟合，那么减少特征的数量就很有意义。但是，如果我们不知道在特征选择过程中要消除哪些输入，该怎么办？在这种情况下，正则化方法会特别有用。正则化会“惩罚”系数较大的输入参数，从而限制模型中的方差。虽然有许多正则化方法，例如套索正则化、岭回归和随机失活，但它们都旨在识别并减少数据中的噪声。
集成方法：集成学习方法由一组分类器（例如决策树）组成，会汇总它们的预测结果，识别出现频率最高的结果。最著名的集成方法是 bagging 和 boosting。在装袋中，在 Bagging 方法中，用替换法来选择训练集中的随机数据样本，这意味着可多次选择单个数据点。在生成多个数据样本后，将单独训练这些模型，根据任务类型（如回归或分类），这些预测一般或大多数都会产生更准确的估计值。这通常用于减少噪声数据集中的方差。
请参阅 IBM Developer 图像识别教程，了解如何利用其中的一些方法
# 最近的研究
上文介绍了过拟合的公认定义，但最近的研究（链接位于 IBM 外部）表明，复杂的模型（如深度学习模型和神经网络）尽管被训练为“完全拟合或插值”，但仍能以高精度运行。这一发现与该主题下的历史研究结果不一致，下面的“双下降”风险曲线作了进一步解释。您可以看到，当模型学习超过插值阈值时，模型的性能会提高。我们前面提到的避免过拟合的方法，例如早停法和正则化，实际上可以防止插值。


